{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Classification\n",
    "author : Kobe Thonissen\n",
    "\n",
    "e-mail : kobe.thonissen@gmail.com\n",
    "\n",
    "course : LINFO2263 - Computational Linguistics\n",
    "\n",
    "disclaimer : the function \"remove_html_tags\" and a part of the function \"tokenize\" were offered by the professor (Pierre Dupont) and/or the course assistants (Amaury Fierens and Beno√Æt Ronval)\n",
    "\n",
    "## Project Overview\n",
    "The goal of this project is to classify a dataset of 60k questions from Stack Overflow into one out of two categories: \n",
    "- High quality questions (HQ): Questions that received a high number of upvotes and comments, indicating community engagement\n",
    "- Low quality questions (LQ): Questions that received less interaction from the community\n",
    "\n",
    "This project explores three different approaches to text classification:\n",
    "\n",
    "- Naive Bayes Classification: A probabilistic classifier based on Bayes' theorem that assumes independence between features\n",
    "- Binary Naive Bayes classification: A variation where each word is counted only once regardless of frequency\n",
    "- Naive Bayes Classification with negative tokens: An enhanced version that accounts for negation in language\n",
    "\n",
    "The Binary Naive Bayes Classifier resulted in the highest accuracy rate (82.649). The Naive Bayes Classifier performed slightly worse (79.547), and the inclusion on negation tokens did not improve the accuracy (79.883)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "This section handles data loading and text preprocessing steps needed before classification:\n",
    "1. Loading the dataset from CSV files\n",
    "2. Cleaning HTML tags from questions\n",
    "3. Tokenizing text into individual words\n",
    "4. Creating a vocabulary to replace infrequent words (n<5>) by the special token <UNK>\n",
    "5. Converting tokenized text into bag-of-words representations (a list containing the individual words of the text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and functions\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import math\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist, ConditionalProbDist\n",
    "from nltk import MLEProbDist\n",
    "from nltk.lm.vocabulary import Vocabulary\n",
    "from nltk.lm import MLE, Laplace\n",
    "from nltk.metrics.scores import accuracy\n",
    "\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"\n",
    "    Removes HTML tags from text (any sequence of characters between < and >).\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text containing HTML tags\n",
    "        \n",
    "    Returns:\n",
    "        str: Clean text with HTML tags removed\n",
    "    \"\"\"\n",
    "    import re\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "\n",
    "def tokenize(path):\n",
    "    \"\"\"\n",
    "    Processes the dataset by removing HTML tags and tokenizing the text.\n",
    "    \n",
    "    Args:\n",
    "        path (str): Path to a CSV file containing columns \"Text\" (with HTML-formatted text) and \"Y\" (quality label)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Processed pandas dataframe with:\n",
    "        - HTML tags removed from \"Text\" column\n",
    "        - New \"Tokens\" column containing lists of word tokens\n",
    "    \"\"\"\n",
    "    df_corpus = pd.read_csv(path)\n",
    "    df_corpus['Text'] = df_corpus['Text'].apply(lambda x: remove_html_tags(x))\n",
    "    df_corpus['Tokens'] = df_corpus['Text'].apply(lambda x: WordPunctTokenizer().tokenize(x)).astype('object')\n",
    "    return(df_corpus)\n",
    "\n",
    "def to_bow(df, vocab):\n",
    "    '''\n",
    "    Converts tokenized text to bag-of-words representation, filtering out out-of-vocabulary tokens.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame containing a \"Tokens\" column with lists of tokens\n",
    "        vocab (Vocabulary): NLTK vocabulary object defining valid tokens\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with new \"BOW\" column containing lists of one-tuples for each token\n",
    "    '''\n",
    "    df[\"BOW\"] = \"\"\n",
    "    for i in range(len(df)):\n",
    "        text = df.at[i, \"Tokens\"]\n",
    "        text_without_oov = []\n",
    "        for token in text:\n",
    "            if vocab.lookup(token) != \"<UNK>\":\n",
    "                text_without_oov.append( (token,) )\n",
    "        df.at[i, \"BOW\"] = list(text_without_oov)\n",
    "    return df\n",
    "\n",
    "def create_vocab(df, cutoff):\n",
    "    \"\"\"\n",
    "    Creates a vocabulary from tokens in the dataset, filtering out rare words.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame containing a \"Tokens\" column\n",
    "        cutoff (int): Minimum frequency threshold - tokens appearing less than this will be excluded\n",
    "        \n",
    "    Returns:\n",
    "        Vocabulary: NLTK vocabulary object containing all tokens meeting the frequency threshold\n",
    "    \"\"\"\n",
    "    all_tokens = []\n",
    "    for text in df[\"Tokens\"]:\n",
    "        for token in text:\n",
    "            all_tokens.append(token)\n",
    "    vocab = Vocabulary(all_tokens, unk_cutoff=cutoff)\n",
    "    return(vocab)\n",
    "\n",
    "def logscore(text, model, category_prob):\n",
    "    \"\"\"\n",
    "    Computes log-probability of a text belonging to a category using Naive Bayes principles.\n",
    "    \n",
    "    The function calculates: log P(c) + sum(log P(w_i|c)) where:\n",
    "    - P(c) is the prior probability of category c\n",
    "    - P(w_i|c) is the probability of word w_i given category c\n",
    "    \n",
    "    Args:\n",
    "        text (list): List of word tokens (as tuples)\n",
    "        model: Language model that provides word probabilities\n",
    "        category_prob (float): Prior probability of the category\n",
    "        \n",
    "    Returns:\n",
    "        float: Log probability score of the text belonging to the category\n",
    "    \"\"\"\n",
    "    sum = 0\n",
    "    for word in text:\n",
    "        word_prob = model.score(word[0])  # probability of word given category\n",
    "        sum += math.log(word_prob, 10)\n",
    "    return math.log(category_prob, 10) + sum\n",
    "\n",
    "def argmax_category(text, model_lq, model_hq, category_prob):\n",
    "    \"\"\"\n",
    "    Determines the most likely category (HQ or LQ) for a given text.\n",
    "    \n",
    "    Args:\n",
    "        text (list): List of word tokens (as tuples)\n",
    "        model_lq: Language model for low quality questions\n",
    "        model_hq: Language model for high quality questions\n",
    "        category_prob (dict): Prior probabilities for \"HQ\" and \"LQ\" categories\n",
    "        \n",
    "    Returns:\n",
    "        str: Predicted category (\"HQ\" or \"LQ\")\n",
    "    \"\"\"\n",
    "    label_given_text_prob_hq = logscore(text, model_hq, category_prob[\"HQ\"])\n",
    "    label_given_text_prob_lq = logscore(text, model_lq, category_prob[\"LQ\"])\n",
    "    if label_given_text_prob_hq > label_given_text_prob_lq:\n",
    "        return \"HQ\"\n",
    "    else:\n",
    "        return \"LQ\"\n",
    "    \n",
    "def predict_categories(df, model_hq, model_lq, category_prob):\n",
    "    \"\"\"\n",
    "    Predicts categories for all texts in the dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame containing \"BOW\" column with tokenized texts\n",
    "        model_hq: Language model for high quality questions\n",
    "        model_lq: Language model for low quality questions\n",
    "        category_prob (dict): Prior probabilities for \"HQ\" and \"LQ\" categories\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Original dataframe with an additional \"Predicted_Y\" column containing predictions\n",
    "    \"\"\"\n",
    "    df[\"Predicted_Y\"] = df[\"BOW\"].apply(lambda x: argmax_category(x, model_lq, model_hq, category_prob))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize training dataset\n",
    "df_train = tokenize(\"../corpora/train.csv\")\n",
    "df_test = tokenize(\"../corpora/test.csv\")\n",
    "\n",
    "\n",
    "#construct vocabulary, omitting all words with less then 5 occurences\n",
    "vocab_train =create_vocab(df_train, 5)\n",
    "\n",
    "# transform texts into bags of words, omitting OOV-tokens\n",
    "df_train = to_bow(df_train, vocab_train)\n",
    "df_test = to_bow(df_test, vocab_train)\n",
    "\n",
    "# get proportions of HQ and LQ texts in df_train\n",
    "category_prop = df_train['Y'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "Naive Bayes allows to classify texts based on the frequency of words. \n",
    "\n",
    "In this implementation:\n",
    "1. We train separate language models for HQ and LQ questions\n",
    "2. We use Laplace smoothing to handle unseen words\n",
    "3. We work with log probabilities to avoid numerical underflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MLE model with Laplace smoothing for each category\n",
    "df_train_hq = df_train[df_train[\"Y\"]==\"HQ\"]\n",
    "lm_hq = Laplace(order=1, vocabulary=vocab_train)\n",
    "lm_hq.fit(df_train_hq[\"BOW\"].tolist(), vocab_train)\n",
    "\n",
    "df_train_lq = df_train[df_train[\"Y\"]==\"LQ\"]\n",
    "lm_lq = Laplace(order=1, vocabulary=vocab_train)\n",
    "lm_lq.fit(df_train_lq[\"BOW\"].tolist(), vocab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results training data:\n",
      "Y              HQ    LQ\n",
      "Predicted_Y            \n",
      "HQ           3588  1458\n",
      "LQ            366  6407\n",
      "results test data:\n",
      "Y             HQ   LQ\n",
      "Predicted_Y          \n",
      "HQ           172  352\n",
      "LQ           231  438\n",
      "accuracy test data:\n",
      "79.547\n"
     ]
    }
   ],
   "source": [
    "# predict category\n",
    "df_train_prediction = predict_categories(df_train, lm_hq, lm_lq, category_prop)\n",
    "df_test_prediction = predict_categories(df_test, lm_hq, lm_lq, category_prop)\n",
    "\n",
    "# present results\n",
    "print(\"results training data:\")\n",
    "print(pd.crosstab(df_train_prediction[\"Predicted_Y\"], df_train_prediction[\"Y\"]))\n",
    "print(\"results test data:\")\n",
    "print(pd.crosstab(df_test_prediction[\"Predicted_Y\"], df_train_prediction[\"Y\"]))\n",
    "print(\"accuracy test data:\")\n",
    "accuracy_test = accuracy(df_test_prediction[\"Y\"].tolist(), df_test_prediction[\"Predicted_Y\"].tolist())*100\n",
    "print(round(accuracy_test, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Naive Bayes\n",
    "This section implements Binary Naive Bayes classification, a variant of the standard approach.\n",
    "\n",
    "The key difference in Binary Naive Bayes is that we only consider the presence or absence \n",
    "of a word, not its frequency within a document. This means each word is counted at most once\n",
    "per document, regardless of how many times it appears.\n",
    "\n",
    "This approach:\n",
    "1. Reduces the impact of word repetition in longer documents\n",
    "2. May perform better for certain types of text where the mere presence of certain terms\n",
    "   is more important than their frequency\n",
    "3. Often has lower variance in performance across different document lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "def to_unique_bow(df, vocab):\n",
    "    '''\n",
    "    remove OOV-tokens from text\n",
    "    create set: no token occurs multiple times\n",
    "    transform list of words into list of tuples containing individual words\n",
    "    '''\n",
    "    df[\"BOW\"] = \"\"\n",
    "    for i in range(len(df)):\n",
    "        text = df.at[i, \"Tokens\"]\n",
    "        text_without_oov = []\n",
    "        for token in text:\n",
    "            if vocab.lookup(token) != \"<UNK>\":\n",
    "                text_without_oov.append( (token,) )\n",
    "        set_text = list(set(text_without_oov))\n",
    "        df.at[i, \"BOW\"] = list(set_text)\n",
    "    return df\n",
    "\n",
    "\n",
    "# tokenize training dataset\n",
    "df_train = tokenize(\"../corpora/train.csv\")\n",
    "df_test = tokenize(\"../corpora/test.csv\")\n",
    "\n",
    "\n",
    "#construct vocabulary, omitting all words with less then 5 occurences\n",
    "vocab_train =create_vocab(df_train, 5)\n",
    "\n",
    "# transform texts into bags of words, omitting OOV-tokens\n",
    "df_train = to_unique_bow(df_train, vocab_train)\n",
    "df_test = to_unique_bow(df_test, vocab_train)\n",
    "\n",
    "# get proportions of HQ and LQ texts in df_train\n",
    "category_prop = df_train['Y'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MLE model with Laplace smoothing for each category\n",
    "df_train_hq = df_train[df_train[\"Y\"]==\"HQ\"]\n",
    "lm_hq = Laplace(order=1, vocabulary=vocab_train)\n",
    "lm_hq.fit(df_train_hq[\"BOW\"].tolist(), vocab_train)\n",
    "\n",
    "df_train_lq = df_train[df_train[\"Y\"]==\"LQ\"]\n",
    "lm_lq = Laplace(order=1, vocabulary=vocab_train)\n",
    "lm_lq.fit(df_train_lq[\"BOW\"].tolist(), vocab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results training data:\n",
      "Y              HQ    LQ\n",
      "Predicted_Y            \n",
      "HQ           3513   997\n",
      "LQ            441  6868\n",
      "results test data:\n",
      "Y             HQ   LQ\n",
      "Predicted_Y          \n",
      "HQ           141  316\n",
      "LQ           262  474\n",
      "accuracy test data:\n",
      "82.649\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# predict category\n",
    "df_train_prediction = predict_categories(df_train, lm_hq, lm_lq, category_prop)\n",
    "df_test_prediction = predict_categories(df_test, lm_hq, lm_lq, category_prop)\n",
    "\n",
    "# present results\n",
    "print(\"results training data:\")\n",
    "print(pd.crosstab(df_train_prediction[\"Predicted_Y\"], df_train_prediction[\"Y\"]))\n",
    "print(\"results test data:\")\n",
    "print(pd.crosstab(df_test_prediction[\"Predicted_Y\"], df_train_prediction[\"Y\"]))\n",
    "print(\"accuracy test data:\")\n",
    "accuracy_test = accuracy(df_test_prediction[\"Y\"].tolist(), df_test_prediction[\"Predicted_Y\"].tolist())*100\n",
    "print(round(accuracy_test, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative tokens\n",
    "This section enhances Naive Bayes classification by incorporating negation handling.\n",
    "\n",
    "Negation can significantly alter the meaning of text, but standard bag-of-words models\n",
    "don't capture this nuance. For example, \"good\" and \"not good\" have opposite meanings\n",
    "but would be treated as independent features in standard models.\n",
    "\n",
    "This implementation:\n",
    "1. Identifies negative contexts (words appearing after negative words like 'not', 'no', 'never')\n",
    "2. Marks words in negative contexts with a \"_NOT\" suffix, creating distinct features\n",
    "3. Treats these marked words as separate vocabulary items in the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "def to_bow_with_negative_tokens(df, vocab):\n",
    "    '''\n",
    "    remove OOV-tokens from text\n",
    "    transform list of words into list of tuples containing individual words\n",
    "    preprocess the questions so as to replace any token t between a negative token (['not', 'no', 'never']) and a punctuation sign (['.', ',', ':', '?', '!']) by the token t_NOT.\n",
    "    '''\n",
    "    df[\"BOW\"] = \"\"\n",
    "    for i in range(len(df)):\n",
    "        text = df.at[i, \"Tokens\"]\n",
    "        text_without_oov = []\n",
    "        negative_context = False\n",
    "        for token in text:\n",
    "            if token in ['not', 'no', 'never']:\n",
    "                negative_context=True\n",
    "            if token in ['.', ',', ':', '?', '!']:\n",
    "                negative_context=False\n",
    "            if vocab.lookup(token) != \"<UNK>\":\n",
    "                if negative_context:\n",
    "                    token = token + \"_NOT\"\n",
    "                text_without_oov.append( (token,) )\n",
    "        df.at[i, \"BOW\"] = list(text_without_oov)\n",
    "    return df\n",
    "\n",
    "\n",
    "# tokenize training dataset\n",
    "df_train = tokenize(\"../corpora/train.csv\")\n",
    "df_test = tokenize(\"../corpora/test.csv\")\n",
    "\n",
    "\n",
    "#construct vocabulary, omitting all words with less then 5 occurences\n",
    "vocab_train =create_vocab(df_train, 5)\n",
    "\n",
    "# transform texts into bags of words, omitting OOV-tokens\n",
    "df_train = to_bow_with_negative_tokens(df_train, vocab_train)\n",
    "df_test = to_bow_with_negative_tokens(df_test, vocab_train)\n",
    "\n",
    "# get proportions of HQ and LQ texts in df_train\n",
    "category_prop = df_train['Y'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MLE model with Laplace smoothing for each category\n",
    "df_train_hq = df_train[df_train[\"Y\"]==\"HQ\"]\n",
    "lm_hq = Laplace(order=1, vocabulary=vocab_train)\n",
    "lm_hq.fit(df_train_hq[\"BOW\"].tolist(), vocab_train)\n",
    "\n",
    "df_train_lq = df_train[df_train[\"Y\"]==\"LQ\"]\n",
    "lm_lq = Laplace(order=1, vocabulary=vocab_train)\n",
    "lm_lq.fit(df_train_lq[\"BOW\"].tolist(), vocab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results training data:\n",
      "Y              HQ    LQ\n",
      "Predicted_Y            \n",
      "HQ           3578  1471\n",
      "LQ            376  6394\n",
      "results test data:\n",
      "Y             HQ   LQ\n",
      "Predicted_Y          \n",
      "HQ           169  355\n",
      "LQ           234  435\n",
      "accuracy test data:\n",
      "79.883\n"
     ]
    }
   ],
   "source": [
    "# predict category\n",
    "df_train_prediction = predict_categories(df_train, lm_hq, lm_lq, category_prop)\n",
    "df_test_prediction = predict_categories(df_test, lm_hq, lm_lq, category_prop)\n",
    "\n",
    "# present results\n",
    "print(\"results training data:\")\n",
    "print(pd.crosstab(df_train_prediction[\"Predicted_Y\"], df_train_prediction[\"Y\"]))\n",
    "print(\"results test data:\")\n",
    "print(pd.crosstab(df_test_prediction[\"Predicted_Y\"], df_train_prediction[\"Y\"]))\n",
    "print(\"accuracy test data:\")\n",
    "accuracy_test = accuracy(df_test_prediction[\"Y\"].tolist(), df_test_prediction[\"Predicted_Y\"].tolist())*100\n",
    "print(round(accuracy_test, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Question Classification)",
   "language": "python",
   "name": "question-classification-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
